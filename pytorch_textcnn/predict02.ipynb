{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['宝宝食品', '个人洗护']\n"
     ]
    }
   ],
   "source": [
    "# coding: UTF-8\n",
    "import torch\n",
    "from importlib import import_module\n",
    "import pickle as pkl\n",
    "\n",
    "class CnnModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        dataset = 'dataset'  # 数据集\n",
    "        embedding = 'random'\n",
    "        model_name = 'TextCNN'  # 'TextRCNN'  # TextCNN, TextRNN, FastText, TextRCNN, TextRNN_Att, DPCNN, Transformer\n",
    "        self.id_to_cate = id_to_cate = {int(x.split(\" +++$+++ \")[1]\\\n",
    "            .strip()):x.split(\" +++$+++ \")[0] for x in open(dataset \\\n",
    "            + '/data/id_to_cate.txt', encoding='utf-8').readlines()}\n",
    "        x = import_module(model_name)\n",
    "        config = x.Config(dataset, embedding)\n",
    "        self.vocab = pkl.load(open(config.vocab_path, 'rb'))\n",
    "        config.n_vocab = len(self.vocab)\n",
    "        self.model = x.Model(config).to(config.device)\n",
    "\n",
    "        self.model.load_state_dict(torch.load(config.save_path))\n",
    "        self.model.eval()\n",
    "\n",
    "    def load_dataset(self,message, pad_size=32):\n",
    "        UNK, PAD = '<UNK>', '<PAD>'  # 未知字，padding符号\n",
    "        tokenizer = lambda x: [y for y in x]\n",
    "        contents = []\n",
    "        for line in message:\n",
    "            words_line = []\n",
    "            token = tokenizer(line)\n",
    "            seq_len = len(token)\n",
    "            if pad_size:\n",
    "                if len(token) < pad_size:\n",
    "                    token.extend([PAD] * (pad_size - len(token)))\n",
    "                else:\n",
    "                    token = token[:pad_size]\n",
    "                    seq_len = pad_size\n",
    "            # word to id\n",
    "            for word in token:\n",
    "                words_line.append(self.vocab.get(word, self.vocab.get(UNK)))\n",
    "            contents.append(words_line)\n",
    "        return torch.LongTensor(contents),\"placeholder\"\n",
    "\n",
    "    def predict(self,message):\n",
    "        if type(message) == str:\n",
    "            message = [message]\n",
    "        content = self.load_dataset(message)\n",
    "        outputs = self.model(content)\n",
    "        predict_int = torch.max(outputs.data, 1)[1].cpu().numpy()\n",
    "        # id to category\n",
    "        predict_class = [self.id_to_cate[i] for i in predict_int]\n",
    "\n",
    "        return predict_class\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    cnn_model = CnnModel()\n",
    "    test_demo = ['美国Nordic Naturals 儿童草莓味DHA鳕鱼油口服液 119ml',\n",
    "                 'DERMACEPT C10铂金抗氧套装']\n",
    "    print(cnn_model.predict(test_demo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = [[cnn_model.id_to_cate[int(x.split(\" +++$+++ \")[1]\\\n",
    "            .strip())],x.split(\" +++$+++ \")[0]] for x in open('dataset/data/test.txt', encoding='utf-8').readlines()]\n",
    "x = [i[1] for i in testfile]\n",
    "y = [i[0] for i in testfile]\n",
    "predict_class = cnn_model.predict(x)\n",
    "from sklearn import metrics\n",
    "acc = metrics.accuracy_score(y, predict_class)\n",
    "report = metrics.classification_report(y, predict_class, digits=4)\n",
    "confusion = metrics.confusion_matrix(y, predict_class)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       个人洗护     0.9310    0.8966    0.9135       783\n",
      "        保健品     0.9479    0.9673    0.9575       979\n",
      "       口腔护理     0.9545    0.9492    0.9518       177\n",
      "    女装/女士内衣     0.9749    0.9749    0.9749       399\n",
      "      婴幼儿奶粉     0.9718    0.9773    0.9745       176\n",
      "      孕产妇用品     0.9540    0.9326    0.9432        89\n",
      "    宝宝服饰/玩具     0.9818    0.9600    0.9708       225\n",
      "       宝宝洗护     0.9646    0.8934    0.9277       244\n",
      "  宝宝用品_含纸尿片     0.9890    0.9756    0.9823       369\n",
      "       宝宝食品     0.9176    0.8830    0.9000       265\n",
      "    宠物食品/用品     0.9909    0.9559    0.9731       227\n",
      "       家用家电     0.9481    0.9481    0.9481       135\n",
      "       居家日用     0.9185    0.9390    0.9286       672\n",
      "      彩妆/香水     0.9381    0.9739    0.9556      1073\n",
      "       护理护肤     0.9494    0.9574    0.9533      1665\n",
      "       数码3C     0.9550    0.9725    0.9636       109\n",
      "       汽车用品     1.0000    0.5556    0.7143         9\n",
      "         油品     1.0000    0.9595    0.9793        74\n",
      "    男装/男士内衣     0.9912    0.9869    0.9890       457\n",
      "      箱包/鞋靴     0.9914    0.9961    0.9937      1266\n",
      "       美容工具     0.9655    0.8750    0.9180        96\n",
      "       运动户外     1.0000    0.9741    0.9869       309\n",
      "       进口食品     0.9289    0.9007    0.9146       725\n",
      "       进口饮料     0.9179    0.8883    0.9029       403\n",
      "      餐厨/清洁     0.9200    0.9758    0.9471       495\n",
      "      饰品/手表     0.9692    0.9844    0.9767       639\n",
      "\n",
      "avg / total     0.9542    0.9541    0.9539     12060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"获取已使用时间\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time usage: 0:00:04\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cnn_model = CnnModel()\n",
    "test_demo = ['美国Nordic Naturals 儿童草莓味DHA鳕鱼油口服液 119ml']\n",
    "print(cnn_model.predict(test_demo))\n",
    "time_dif = get_time_dif(start_time)\n",
    "print(\"Time usage:\", time_dif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
