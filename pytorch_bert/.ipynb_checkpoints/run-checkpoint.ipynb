{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "322it [00:00, 3215.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96456it [00:25, 3779.19it/s]\n",
      "12051it [00:03, 3967.51it/s]\n",
      "12060it [00:03, 3971.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time usage: 0:00:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: UTF-8\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from train_eval import train, init_network\n",
    "from importlib import import_module\n",
    "from utils import build_dataset, build_iterator, get_time_dif\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = 'dataset'  # 数据集\n",
    "    model_name = 'bert'  # bert\n",
    "    x = import_module(model_name)\n",
    "    config = x.Config(dataset)\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "    torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Loading data...\")\n",
    "    train_data, dev_data, test_data = build_dataset(config)\n",
    "    train_iter = build_iterator(train_data, config)\n",
    "    dev_iter = build_iterator(dev_data, config)\n",
    "    test_iter = build_iterator(test_data, config)\n",
    "    time_dif = get_time_dif(start_time)\n",
    "    print(\"Time usage:\", time_dif)\n",
    "\n",
    "    # train\n",
    "    model = x.Model(config).to(config.device)\n",
    "    train(config, model, train_iter, dev_iter, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colab ouput 2020-12-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test Loss:  0.14,  Test Acc: 96.62%\n",
    "Precision, Recall and F1-Score...\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        个人洗护     0.9123    0.9566    0.9339       783\n",
    "         保健品     0.9693    0.9663    0.9678       979\n",
    "        口腔护理     0.9558    0.9774    0.9665       177\n",
    "     女装/女士内衣     0.9950    0.9950    0.9950       399\n",
    "       婴幼儿奶粉     0.9830    0.9830    0.9830       176\n",
    "       孕产妇用品     0.9670    0.9888    0.9778        89\n",
    "     宝宝服饰/玩具     1.0000    0.9956    0.9978       225\n",
    "        宝宝洗护     0.9386    0.8770    0.9068       244\n",
    "   宝宝用品_含纸尿片     0.9732    0.9837    0.9784       369\n",
    "        宝宝食品     0.8826    0.9358    0.9084       265\n",
    "     宠物食品/用品     0.9912    0.9868    0.9890       227\n",
    "        家用家电     0.9254    0.9185    0.9219       135\n",
    "        居家日用     0.9652    0.9494    0.9572       672\n",
    "       彩妆/香水     0.9775    0.9730    0.9752      1073\n",
    "        护理护肤     0.9617    0.9658    0.9637      1665\n",
    "        数码3C     0.9727    0.9817    0.9772       109\n",
    "        汽车用品     1.0000    0.4444    0.6154         9\n",
    "          油品     1.0000    1.0000    1.0000        74\n",
    "     男装/男士内衣     0.9956    0.9978    0.9967       457\n",
    "       箱包/鞋靴     0.9976    0.9984    0.9980      1266\n",
    "        美容工具     0.9231    0.8750    0.8984        96\n",
    "        运动户外     0.9935    0.9871    0.9903       309\n",
    "        进口食品     0.9559    0.8979    0.9260       725\n",
    "        进口饮料     0.9401    0.9355    0.9378       403\n",
    "       餐厨/清洁     0.9432    0.9737    0.9583       495\n",
    "       饰品/手表     0.9845    0.9937    0.9891       639\n",
    "\n",
    "    accuracy                         0.9662     12060\n",
    "   macro avg     0.9655    0.9438    0.9504     12060\n",
    "weighted avg     0.9664    0.9662    0.9661     12060\n",
    "\n",
    "Confusion Matrix...\n",
    "[[ 749    0    0    0    0    0    0    6    1    0    0    0    0    3\n",
    "    20    0    0    0    0    0    2    0    1    1    0    0]\n",
    " [   1  946    0    1    0    1    0    0    0    3    1    0    2    1\n",
    "     7    0    0    0    0    0    0    0   12    2    2    0]\n",
    " [   4    0  173    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    1    0  397    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0  173    0    0    0    1    1    0    0    0    0\n",
    "     0    0    0    0    0    1    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0   88    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    1    0    0]\n",
    " [   0    0    0    0    0    0  224    1    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [  16    0    0    0    0    0    0  214    2    1    0    0    1    1\n",
    "     5    0    0    0    0    0    0    0    1    0    1    2]\n",
    " [   0    0    0    0    0    0    0    1  363    1    0    0    2    0\n",
    "     0    0    0    0    0    0    0    0    1    0    1    0]\n",
    " [   0    8    0    0    0    0    0    1    2  248    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    4    0    1    0]\n",
    " [   0    0    3    0    0    0    0    0    0    0  224    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    2    0    0    0    0    0    0    0    0  124    1    0\n",
    "     0    2    0    0    0    0    2    0    0    0    4    0]\n",
    " [   6    1    0    0    0    0    0    0    0    0    0    1  638    2\n",
    "     2    1    0    0    0    0    1    1    0    1   13    5]\n",
    " [   7    0    0    0    0    0    0    2    0    0    0    0    3 1044\n",
    "    14    0    0    0    0    0    0    1    0    2    0    0]\n",
    " [  29    3    3    0    0    0    0    3    0    1    1    0    2    8\n",
    "  1608    0    0    0    0    0    1    0    4    1    0    1]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    1    0\n",
    "     0  107    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    2    0\n",
    "     0    0    4    0    0    0    0    0    0    0    1    1]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0   74    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0  456    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    1 1264    0    0    1    0    0    0]\n",
    " [   2    0    0    0    0    1    0    0    0    0    0    3    1    3\n",
    "     2    0    0    0    0    0   84    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    1    0    0    1    0    0\n",
    "     0    0    0    0    0    1    0  305    0    0    0    1]\n",
    " [   5   14    0    0    0    0    0    0    0   23    0    0    2    1\n",
    "     7    0    0    0    0    1    0    0  651   16    5    0]\n",
    " [   2    3    0    0    3    1    0    0    1    3    0    0    0    1\n",
    "     5    0    0    0    0    0    0    0    6  377    1    0]\n",
    " [   0    0    0    0    0    0    0    0    2    0    0    3    6    0\n",
    "     1    0    0    0    0    0    1    0    0    0  482    0]\n",
    " [   0    0    0    1    0    0    0    0    0    0    0    0    0    1\n",
    "     1    0    0    0    1    0    0    0    0    0    0  635]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colab ouput old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "580it [00:00, 5795.92it/s]Loading data...\n",
    "96456it [00:15, 6046.62it/s]\n",
    "12051it [00:02, 5816.34it/s]\n",
    "12060it [00:01, 6554.05it/s]\n",
    "Time usage: 0:00:20\n",
    "Epoch [1/3]\n",
    "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
    "\tadd_(Number alpha, Tensor other)\n",
    "Consider using one of the following signatures instead:\n",
    "\tadd_(Tensor other, *, Number alpha)\n",
    "Iter:      0,  Train Loss:   3.3,  Train Acc:  3.12%,  Val Loss:   3.3,  Val Acc:  3.81%,  Time: 0:00:44 *\n",
    "Iter:    100,  Train Loss:  0.61,  Train Acc: 88.28%,  Val Loss:  0.58,  Val Acc: 85.79%,  Time: 0:03:50 *\n",
    "Iter:    200,  Train Loss:   0.3,  Train Acc: 92.97%,  Val Loss:  0.37,  Val Acc: 90.61%,  Time: 0:06:57 *\n",
    "Iter:    300,  Train Loss:  0.31,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 92.87%,  Time: 0:10:04 *\n",
    "Iter:    400,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.25,  Val Acc: 93.78%,  Time: 0:13:10 *\n",
    "Iter:    500,  Train Loss:  0.23,  Train Acc: 95.31%,  Val Loss:  0.22,  Val Acc: 94.33%,  Time: 0:16:16 *\n",
    "Iter:    600,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.21,  Val Acc: 94.71%,  Time: 0:19:22 *\n",
    "Iter:    700,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.19,  Val Acc: 95.25%,  Time: 0:22:28 *\n",
    "Epoch [2/3]\n",
    "Iter:    800,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.17,  Val Acc: 95.86%,  Time: 0:25:34 *\n",
    "Iter:    900,  Train Loss: 0.052,  Train Acc: 99.22%,  Val Loss:  0.16,  Val Acc: 95.68%,  Time: 0:28:39 *\n",
    "Iter:   1000,  Train Loss:   0.2,  Train Acc: 96.09%,  Val Loss:  0.15,  Val Acc: 96.17%,  Time: 0:31:45 *\n",
    "Iter:   1100,  Train Loss: 0.062,  Train Acc: 97.66%,  Val Loss:  0.14,  Val Acc: 96.32%,  Time: 0:34:51 *\n",
    "Iter:   1200,  Train Loss: 0.082,  Train Acc: 97.66%,  Val Loss:  0.14,  Val Acc: 96.32%,  Time: 0:37:56 \n",
    "Iter:   1300,  Train Loss:  0.29,  Train Acc: 94.53%,  Val Loss:  0.14,  Val Acc: 96.51%,  Time: 0:41:03 *\n",
    "Iter:   1400,  Train Loss: 0.064,  Train Acc: 98.44%,  Val Loss:  0.13,  Val Acc: 96.55%,  Time: 0:44:09 *\n",
    "Iter:   1500,  Train Loss:  0.11,  Train Acc: 97.66%,  Val Loss:  0.13,  Val Acc: 96.78%,  Time: 0:47:14 *\n",
    "Epoch [3/3]\n",
    "Iter:   1600,  Train Loss:   0.2,  Train Acc: 95.31%,  Val Loss:  0.12,  Val Acc: 96.83%,  Time: 0:50:20 *\n",
    "Iter:   1700,  Train Loss: 0.027,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.07%,  Time: 0:53:26 *\n",
    "Iter:   1800,  Train Loss: 0.0079,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.20%,  Time: 0:56:31 *\n",
    "Iter:   1900,  Train Loss: 0.044,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.23%,  Time: 0:59:38 *\n",
    "Iter:   2000,  Train Loss: 0.011,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.20%,  Time: 1:02:44 *\n",
    "Iter:   2100,  Train Loss: 0.049,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.37%,  Time: 1:05:50 *\n",
    "Iter:   2200,  Train Loss: 0.015,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.29%,  Time: 1:08:57 *\n",
    "Test Loss:  0.11,  Test Acc: 97.33%\n",
    "Precision, Recall and F1-Score...\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        个人洗护     0.9354    0.9617    0.9484       783\n",
    "         保健品     0.9696    0.9765    0.9730       979\n",
    "        口腔护理     0.9670    0.9944    0.9805       177\n",
    "     女装/女士内衣     0.9900    0.9975    0.9938       399\n",
    "       婴幼儿奶粉     0.9669    0.9943    0.9804       176\n",
    "       孕产妇用品     0.9457    0.9775    0.9613        89\n",
    "     宝宝服饰/玩具     0.9825    1.0000    0.9912       225\n",
    "        宝宝洗护     0.9414    0.9221    0.9317       244\n",
    "   宝宝用品_含纸尿片     0.9785    0.9864    0.9825       369\n",
    "        宝宝食品     0.9104    0.9585    0.9338       265\n",
    "     宠物食品/用品     0.9956    0.9868    0.9912       227\n",
    "        家用家电     0.9769    0.9407    0.9585       135\n",
    "        居家日用     0.9758    0.9583    0.9670       672\n",
    "       彩妆/香水     0.9823    0.9814    0.9818      1073\n",
    "        护理护肤     0.9740    0.9664    0.9702      1665\n",
    "        数码3C     0.9727    0.9817    0.9772       109\n",
    "        汽车用品     1.0000    0.8889    0.9412         9\n",
    "          油品     0.9867    1.0000    0.9933        74\n",
    "     男装/男士内衣     0.9978    0.9978    0.9978       457\n",
    "       箱包/鞋靴     0.9984    0.9992    0.9988      1266\n",
    "        美容工具     0.9785    0.9479    0.9630        96\n",
    "        运动户外     0.9967    0.9871    0.9919       309\n",
    "        进口食品     0.9653    0.9214    0.9428       725\n",
    "        进口饮料     0.9513    0.9206    0.9357       403\n",
    "       餐厨/清洁     0.9476    0.9859    0.9663       495\n",
    "       饰品/手表     0.9906    0.9937    0.9922       639\n",
    "\n",
    "    accuracy                         0.9733     12060\n",
    "   macro avg     0.9722    0.9703    0.9710     12060\n",
    "weighted avg     0.9734    0.9733    0.9733     12060\n",
    "\n",
    "Confusion Matrix...\n",
    "[[ 753    0    0    0    0    0    1    7    1    0    0    0    0    2\n",
    "    17    0    0    0    0    0    0    0    1    1    0    0]\n",
    " [   1  956    0    1    1    1    0    0    0    5    0    0    1    1\n",
    "     3    0    0    0    0    0    0    0    5    1    2    1]\n",
    " [   1    0  176    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    1    0  398    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0  175    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    1    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0   87    0    1    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    1    0    0]\n",
    " [   0    0    0    0    0    0  225    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [  10    0    0    0    0    0    0  225    3    0    0    0    0    1\n",
    "     3    0    0    0    0    0    0    0    1    0    1    0]\n",
    " [   0    0    0    0    0    0    2    1  364    1    0    0    1    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    2    0    0    1    0    0    1    2  254    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    4    0    0    0]\n",
    " [   0    0    2    0    0    0    0    0    0    0  224    0    0    0\n",
    "     1    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    1    0    0    0    0    0    1    0    0  127    2    0\n",
    "     0    1    0    0    0    0    1    0    0    0    2    0]\n",
    " [   3    1    0    0    0    0    1    0    0    0    0    0  644    2\n",
    "     1    0    0    0    0    0    1    0    0    1   14    4]\n",
    " [   6    0    0    0    0    0    0    1    0    0    0    0    2 1053\n",
    "     8    0    0    0    0    0    0    1    0    1    1    0]\n",
    " [  26    5    3    1    0    1    0    3    0    1    0    0    2    7\n",
    "  1609    0    0    0    0    0    0    0    7    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    1    0\n",
    "     0  107    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    8    0    0    0    0    0    0    0    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0   74    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0  456    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    1 1265    0    0    0    0    0    0]\n",
    " [   1    0    0    0    0    1    0    0    0    0    0    1    0    1\n",
    "     0    0    0    0    0    0   91    0    0    0    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    2    0\n",
    "     0    1    0    0    0    0    0  305    1    0    0    0]\n",
    " [   3    9    0    0    0    0    0    0    0   16    1    0    2    0\n",
    "     6    1    0    0    0    1    0    0  668   14    4    0]\n",
    " [   1   12    0    0    4    2    0    0    1    2    0    0    0    2\n",
    "     2    0    0    0    0    0    0    0    5  371    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    3    0\n",
    "     1    0    0    1    0    0    0    0    0    0  488    1]\n",
    " [   0    0    0    2    0    0    0    0    0    0    0    0    0    1\n",
    "     1    0    0    0    0    0    0    0    0    0    0  635]]\n",
    "Time usage: 0:00:43"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
