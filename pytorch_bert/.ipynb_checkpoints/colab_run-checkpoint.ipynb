{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colab ouput 2020-12-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch [1/8]\n",
    "Iter:      0,  Train Loss:   3.3,  Train Acc:  7.03%,  Val Loss:   3.3,  Val Acc:  4.02%,  Time: 0:00:20 *\n",
    "Iter:    100,  Train Loss:   0.9,  Train Acc: 78.91%,  Val Loss:  0.76,  Val Acc: 82.70%,  Time: 0:01:43 *\n",
    "Iter:    200,  Train Loss:  0.39,  Train Acc: 92.97%,  Val Loss:  0.44,  Val Acc: 90.03%,  Time: 0:03:10 *\n",
    "Iter:    300,  Train Loss:  0.39,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 92.04%,  Time: 0:04:39 *\n",
    "Iter:    400,  Train Loss:  0.32,  Train Acc: 95.31%,  Val Loss:  0.28,  Val Acc: 93.46%,  Time: 0:06:10 *\n",
    "Iter:    500,  Train Loss:  0.33,  Train Acc: 92.97%,  Val Loss:  0.24,  Val Acc: 93.99%,  Time: 0:07:42 *\n",
    "Iter:    600,  Train Loss:  0.31,  Train Acc: 91.41%,  Val Loss:  0.22,  Val Acc: 94.47%,  Time: 0:09:13 *\n",
    "Iter:    700,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:   0.2,  Val Acc: 94.90%,  Time: 0:10:45 *\n",
    "Epoch [2/8]\n",
    "Iter:    800,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.19,  Val Acc: 95.27%,  Time: 0:12:17 *\n",
    "Iter:    900,  Train Loss: 0.082,  Train Acc: 97.66%,  Val Loss:  0.19,  Val Acc: 95.18%,  Time: 0:13:48 *\n",
    "Iter:   1000,  Train Loss:  0.19,  Train Acc: 96.09%,  Val Loss:  0.17,  Val Acc: 95.59%,  Time: 0:15:20 *\n",
    "Iter:   1100,  Train Loss:   0.1,  Train Acc: 96.88%,  Val Loss:  0.16,  Val Acc: 95.86%,  Time: 0:16:52 *\n",
    "Iter:   1200,  Train Loss:  0.13,  Train Acc: 96.88%,  Val Loss:  0.15,  Val Acc: 96.00%,  Time: 0:18:24 *\n",
    "Iter:   1300,  Train Loss:  0.24,  Train Acc: 94.53%,  Val Loss:  0.15,  Val Acc: 95.98%,  Time: 0:19:55 \n",
    "Iter:   1400,  Train Loss: 0.063,  Train Acc: 98.44%,  Val Loss:  0.15,  Val Acc: 96.20%,  Time: 0:21:27 *\n",
    "Iter:   1500,  Train Loss:   0.1,  Train Acc: 96.09%,  Val Loss:  0.14,  Val Acc: 96.51%,  Time: 0:22:59 *\n",
    "Epoch [3/8]\n",
    "Iter:   1600,  Train Loss:  0.29,  Train Acc: 93.75%,  Val Loss:  0.14,  Val Acc: 96.41%,  Time: 0:24:30 *\n",
    "Iter:   1700,  Train Loss:  0.15,  Train Acc: 96.88%,  Val Loss:  0.14,  Val Acc: 96.56%,  Time: 0:26:02 *\n",
    "Iter:   1800,  Train Loss: 0.016,  Train Acc: 100.00%,  Val Loss:  0.13,  Val Acc: 96.53%,  Time: 0:27:34 *\n",
    "Iter:   1900,  Train Loss:   0.1,  Train Acc: 97.66%,  Val Loss:  0.13,  Val Acc: 96.68%,  Time: 0:29:06 \n",
    "Iter:   2000,  Train Loss: 0.023,  Train Acc: 100.00%,  Val Loss:  0.13,  Val Acc: 96.73%,  Time: 0:30:37 *\n",
    "Iter:   2100,  Train Loss: 0.041,  Train Acc: 99.22%,  Val Loss:  0.13,  Val Acc: 96.66%,  Time: 0:32:09 \n",
    "Iter:   2200,  Train Loss: 0.047,  Train Acc: 99.22%,  Val Loss:  0.13,  Val Acc: 96.85%,  Time: 0:33:40 \n",
    "Epoch [4/8]\n",
    "Iter:   2300,  Train Loss:  0.05,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.14%,  Time: 0:35:11 *\n",
    "Iter:   2400,  Train Loss:  0.14,  Train Acc: 94.53%,  Val Loss:  0.13,  Val Acc: 96.81%,  Time: 0:36:43 \n",
    "Iter:   2500,  Train Loss: 0.057,  Train Acc: 98.44%,  Val Loss:  0.12,  Val Acc: 97.00%,  Time: 0:38:15 \n",
    "Iter:   2600,  Train Loss: 0.038,  Train Acc: 98.44%,  Val Loss:  0.12,  Val Acc: 97.12%,  Time: 0:39:46 \n",
    "Iter:   2700,  Train Loss:  0.02,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.24%,  Time: 0:41:18 \n",
    "Iter:   2800,  Train Loss: 0.037,  Train Acc: 98.44%,  Val Loss:  0.12,  Val Acc: 97.06%,  Time: 0:42:49 \n",
    "Iter:   2900,  Train Loss: 0.057,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.03%,  Time: 0:44:21 \n",
    "Iter:   3000,  Train Loss: 0.067,  Train Acc: 98.44%,  Val Loss:  0.12,  Val Acc: 96.98%,  Time: 0:45:52 \n",
    "Epoch [5/8]\n",
    "Iter:   3100,  Train Loss: 0.047,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.21%,  Time: 0:47:23 *\n",
    "Iter:   3200,  Train Loss: 0.0065,  Train Acc: 100.00%,  Val Loss:  0.12,  Val Acc: 97.19%,  Time: 0:48:55 \n",
    "Iter:   3300,  Train Loss: 0.085,  Train Acc: 96.88%,  Val Loss:  0.12,  Val Acc: 97.38%,  Time: 0:50:26 \n",
    "Iter:   3400,  Train Loss: 0.046,  Train Acc: 97.66%,  Val Loss:  0.12,  Val Acc: 97.36%,  Time: 0:51:57 \n",
    "Iter:   3500,  Train Loss: 0.066,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.36%,  Time: 0:53:29 \n",
    "Iter:   3600,  Train Loss:  0.12,  Train Acc: 97.66%,  Val Loss:  0.12,  Val Acc: 97.34%,  Time: 0:55:00 \n",
    "Iter:   3700,  Train Loss:  0.12,  Train Acc: 97.66%,  Val Loss:  0.12,  Val Acc: 97.34%,  Time: 0:56:32 \n",
    "Epoch [6/8]\n",
    "Iter:   3800,  Train Loss:  0.11,  Train Acc: 97.66%,  Val Loss:  0.12,  Val Acc: 97.38%,  Time: 0:58:03 *\n",
    "Iter:   3900,  Train Loss: 0.056,  Train Acc: 99.22%,  Val Loss:  0.11,  Val Acc: 97.32%,  Time: 0:59:34 *\n",
    "Iter:   4000,  Train Loss: 0.008,  Train Acc: 100.00%,  Val Loss:  0.12,  Val Acc: 97.36%,  Time: 1:01:05 \n",
    "Iter:   4100,  Train Loss: 0.049,  Train Acc: 99.22%,  Val Loss:  0.11,  Val Acc: 97.54%,  Time: 1:02:37 *\n",
    "Iter:   4200,  Train Loss:  0.03,  Train Acc: 99.22%,  Val Loss:  0.11,  Val Acc: 97.59%,  Time: 1:04:08 *\n",
    "Iter:   4300,  Train Loss: 0.049,  Train Acc: 97.66%,  Val Loss:  0.11,  Val Acc: 97.50%,  Time: 1:05:40 \n",
    "Iter:   4400,  Train Loss: 0.093,  Train Acc: 97.66%,  Val Loss:  0.11,  Val Acc: 97.34%,  Time: 1:07:11 \n",
    "Iter:   4500,  Train Loss: 0.006,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.50%,  Time: 1:08:42 *\n",
    "Epoch [7/8]\n",
    "Iter:   4600,  Train Loss: 0.016,  Train Acc: 99.22%,  Val Loss:  0.11,  Val Acc: 97.39%,  Time: 1:10:12 \n",
    "Iter:   4700,  Train Loss: 0.032,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.54%,  Time: 1:11:44 *\n",
    "Iter:   4800,  Train Loss: 0.018,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.49%,  Time: 1:13:15 \n",
    "Iter:   4900,  Train Loss: 0.0044,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.54%,  Time: 1:14:46 \n",
    "Iter:   5000,  Train Loss: 0.0098,  Train Acc: 100.00%,  Val Loss:  0.12,  Val Acc: 97.61%,  Time: 1:16:18 \n",
    "Iter:   5100,  Train Loss: 0.061,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.69%,  Time: 1:17:49 \n",
    "Iter:   5200,  Train Loss: 0.013,  Train Acc: 99.22%,  Val Loss:  0.11,  Val Acc: 97.59%,  Time: 1:19:20 \n",
    "Epoch [8/8]\n",
    "Iter:   5300,  Train Loss: 0.044,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.62%,  Time: 1:20:51 \n",
    "Iter:   5400,  Train Loss: 0.0028,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.55%,  Time: 1:22:23 \n",
    "Iter:   5500,  Train Loss:  0.01,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.62%,  Time: 1:23:55 \n",
    "Iter:   5600,  Train Loss: 0.0091,  Train Acc: 99.22%,  Val Loss:  0.11,  Val Acc: 97.58%,  Time: 1:25:26 \n",
    "Iter:   5700,  Train Loss: 0.0044,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.60%,  Time: 1:26:57 \n",
    "No optimization for a long time, auto-stopping...\n",
    "Test Loss:  0.11,  Test Acc: 97.69%\n",
    "Precision, Recall and F1-Score...\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        个人洗护     0.9482    0.9579    0.9530       783\n",
    "         保健品     0.9755    0.9755    0.9755       979\n",
    "        口腔护理     0.9724    0.9944    0.9832       177\n",
    "     女装/女士内衣     0.9950    0.9950    0.9950       399\n",
    "       婴幼儿奶粉     0.9832    1.0000    0.9915       176\n",
    "       孕产妇用品     0.9565    0.9888    0.9724        89\n",
    "     宝宝服饰/玩具     0.9868    0.9956    0.9912       225\n",
    "        宝宝洗护     0.9623    0.9426    0.9524       244\n",
    "   宝宝用品_含纸尿片     0.9918    0.9783    0.9850       369\n",
    "        宝宝食品     0.9394    0.9358    0.9376       265\n",
    "     宠物食品/用品     1.0000    0.9912    0.9956       227\n",
    "        家用家电     0.9478    0.9407    0.9442       135\n",
    "        居家日用     0.9789    0.9673    0.9731       672\n",
    "       彩妆/香水     0.9778    0.9842    0.9810      1073\n",
    "        护理护肤     0.9730    0.9742    0.9736      1665\n",
    "        数码3C     0.9820    1.0000    0.9909       109\n",
    "        汽车用品     1.0000    0.7778    0.8750         9\n",
    "          油品     1.0000    1.0000    1.0000        74\n",
    "     男装/男士内衣     0.9935    1.0000    0.9967       457\n",
    "       箱包/鞋靴     0.9976    0.9992    0.9984      1266\n",
    "        美容工具     0.9688    0.9688    0.9688        96\n",
    "        运动户外     1.0000    0.9903    0.9951       309\n",
    "        进口食品     0.9609    0.9490    0.9549       725\n",
    "        进口饮料     0.9543    0.9330    0.9435       403\n",
    "       餐厨/清洁     0.9682    0.9838    0.9760       495\n",
    "       饰品/手表     0.9922    0.9937    0.9930       639\n",
    "\n",
    "    accuracy                         0.9769     12060\n",
    "   macro avg     0.9772    0.9699    0.9729     12060\n",
    "weighted avg     0.9769    0.9769    0.9769     12060\n",
    "\n",
    "Confusion Matrix...\n",
    "[[ 750    1    1    0    0    0    0    3    0    0    0    0    0    3\n",
    "    21    0    0    0    0    0    0    0    3    1    0    0]\n",
    " [   2  955    0    0    0    1    0    0    0    3    0    0    1    2\n",
    "     2    0    0    0    1    0    0    0    9    2    0    1]\n",
    " [   1    0  176    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    1    0  397    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0  176    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0   88    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    1    0    0]\n",
    " [   0    0    0    0    0    0  224    1    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   5    0    0    0    0    0    1  230    2    0    0    0    0    2\n",
    "     4    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   2    0    0    0    0    0    2    1  361    1    0    0    1    0\n",
    "     0    0    0    0    0    0    0    0    0    0    1    0]\n",
    " [   0    6    0    0    1    0    0    1    1  248    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    8    0    0    0]\n",
    " [   0    0    2    0    0    0    0    0    0    0  225    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0  127    3    0\n",
    "     0    2    0    0    0    0    1    0    0    0    2    0]\n",
    " [   3    0    0    0    0    0    0    1    0    0    0    1  650    2\n",
    "     3    0    0    0    0    0    1    0    0    1    7    3]\n",
    " [   5    0    0    0    0    0    0    0    0    0    0    0    2 1056\n",
    "     6    0    0    0    0    1    0    0    0    0    2    1]\n",
    " [  18    5    1    0    0    1    0    2    0    1    0    0    2    8\n",
    "  1622    0    0    0    0    0    1    0    2    2    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0  109    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    1    0\n",
    "     0    0    7    0    0    0    0    0    0    0    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0   74    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0  457    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    1 1265    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    1    0    0    0    0    0    1    0    1\n",
    "     0    0    0    0    0    0   93    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    1    0\n",
    "     0    0    0    0    0    1    0  306    0    0    0    0]\n",
    " [   3    4    0    0    0    0    0    0    0    9    0    0    1    1\n",
    "     4    0    0    0    0    1    0    0  688   11    3    0]\n",
    " [   2    7    0    0    2    1    0    0    0    2    0    1    0    3\n",
    "     3    0    0    0    0    0    0    0    6  376    0    0]\n",
    " [   0    0    1    0    0    0    0    0    0    0    0    3    2    0\n",
    "     2    0    0    0    0    0    0    0    0    0  487    0]\n",
    " [   0    0    0    2    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0    1    0    0    0    0    0    0  635]]\n",
    "Time usage: 0:00:22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------分割线-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colab ouput 2020-12-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch [1/3]\n",
    "Iter:      0,  Train Loss:   3.3,  Train Acc:  5.47%,  Val Loss:   3.1,  Val Acc:  9.73%,  Time: 0:00:22 *\n",
    "Iter:    100,  Train Loss:  0.92,  Train Acc: 77.34%,  Val Loss:  0.75,  Val Acc: 82.20%,  Time: 0:01:50 *\n",
    "Iter:    200,  Train Loss:  0.49,  Train Acc: 92.19%,  Val Loss:  0.44,  Val Acc: 90.31%,  Time: 0:03:22 *\n",
    "Iter:    300,  Train Loss:  0.43,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 92.00%,  Time: 0:04:57 *\n",
    "Iter:    400,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 93.05%,  Time: 0:06:31 *\n",
    "Iter:    500,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.27,  Val Acc: 93.89%,  Time: 0:08:05 *\n",
    "Iter:    600,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.25,  Val Acc: 94.22%,  Time: 0:09:40 *\n",
    "Iter:    700,  Train Loss:  0.29,  Train Acc: 93.75%,  Val Loss:  0.22,  Val Acc: 94.53%,  Time: 0:11:14 *\n",
    "Epoch [2/3]\n",
    "Iter:    800,  Train Loss:  0.18,  Train Acc: 96.09%,  Val Loss:   0.2,  Val Acc: 95.18%,  Time: 0:12:48 *\n",
    "Iter:    900,  Train Loss:  0.19,  Train Acc: 95.31%,  Val Loss:  0.19,  Val Acc: 95.37%,  Time: 0:14:23 *\n",
    "Iter:   1000,  Train Loss:  0.11,  Train Acc: 98.44%,  Val Loss:  0.19,  Val Acc: 95.32%,  Time: 0:15:57 *\n",
    "Iter:   1100,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.18,  Val Acc: 95.39%,  Time: 0:17:31 *\n",
    "Iter:   1200,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.17,  Val Acc: 95.69%,  Time: 0:19:06 *\n",
    "Iter:   1300,  Train Loss:   0.2,  Train Acc: 96.88%,  Val Loss:  0.17,  Val Acc: 95.87%,  Time: 0:20:41 *\n",
    "Iter:   1400,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.16,  Val Acc: 95.93%,  Time: 0:22:15 *\n",
    "Iter:   1500,  Train Loss:  0.19,  Train Acc: 96.09%,  Val Loss:  0.15,  Val Acc: 96.17%,  Time: 0:23:49 *\n",
    "Epoch [3/3]\n",
    "Iter:   1600,  Train Loss:  0.22,  Train Acc: 95.31%,  Val Loss:  0.15,  Val Acc: 96.15%,  Time: 0:25:22 \n",
    "Iter:   1700,  Train Loss: 0.046,  Train Acc: 100.00%,  Val Loss:  0.15,  Val Acc: 96.31%,  Time: 0:26:56 *\n",
    "Iter:   1800,  Train Loss:  0.11,  Train Acc: 97.66%,  Val Loss:  0.15,  Val Acc: 96.38%,  Time: 0:28:30 *\n",
    "Iter:   1900,  Train Loss: 0.075,  Train Acc: 98.44%,  Val Loss:  0.14,  Val Acc: 96.37%,  Time: 0:30:04 *\n",
    "Iter:   2000,  Train Loss:  0.13,  Train Acc: 97.66%,  Val Loss:  0.15,  Val Acc: 96.46%,  Time: 0:31:38 \n",
    "Iter:   2100,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.14,  Val Acc: 96.50%,  Time: 0:33:12 *\n",
    "Iter:   2200,  Train Loss: 0.078,  Train Acc: 96.88%,  Val Loss:  0.14,  Val Acc: 96.47%,  Time: 0:34:45 \n",
    "                                \n",
    "\n",
    "Test Loss:  0.14,  Test Acc: 96.62%\n",
    "Precision, Recall and F1-Score...\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        个人洗护     0.9123    0.9566    0.9339       783\n",
    "         保健品     0.9693    0.9663    0.9678       979\n",
    "        口腔护理     0.9558    0.9774    0.9665       177\n",
    "     女装/女士内衣     0.9950    0.9950    0.9950       399\n",
    "       婴幼儿奶粉     0.9830    0.9830    0.9830       176\n",
    "       孕产妇用品     0.9670    0.9888    0.9778        89\n",
    "     宝宝服饰/玩具     1.0000    0.9956    0.9978       225\n",
    "        宝宝洗护     0.9386    0.8770    0.9068       244\n",
    "   宝宝用品_含纸尿片     0.9732    0.9837    0.9784       369\n",
    "        宝宝食品     0.8826    0.9358    0.9084       265\n",
    "     宠物食品/用品     0.9912    0.9868    0.9890       227\n",
    "        家用家电     0.9254    0.9185    0.9219       135\n",
    "        居家日用     0.9652    0.9494    0.9572       672\n",
    "       彩妆/香水     0.9775    0.9730    0.9752      1073\n",
    "        护理护肤     0.9617    0.9658    0.9637      1665\n",
    "        数码3C     0.9727    0.9817    0.9772       109\n",
    "        汽车用品     1.0000    0.4444    0.6154         9\n",
    "          油品     1.0000    1.0000    1.0000        74\n",
    "     男装/男士内衣     0.9956    0.9978    0.9967       457\n",
    "       箱包/鞋靴     0.9976    0.9984    0.9980      1266\n",
    "        美容工具     0.9231    0.8750    0.8984        96\n",
    "        运动户外     0.9935    0.9871    0.9903       309\n",
    "        进口食品     0.9559    0.8979    0.9260       725\n",
    "        进口饮料     0.9401    0.9355    0.9378       403\n",
    "       餐厨/清洁     0.9432    0.9737    0.9583       495\n",
    "       饰品/手表     0.9845    0.9937    0.9891       639\n",
    "\n",
    "    accuracy                         0.9662     12060\n",
    "   macro avg     0.9655    0.9438    0.9504     12060\n",
    "weighted avg     0.9664    0.9662    0.9661     12060\n",
    "\n",
    "Confusion Matrix...\n",
    "[[ 749    0    0    0    0    0    0    6    1    0    0    0    0    3\n",
    "    20    0    0    0    0    0    2    0    1    1    0    0]\n",
    " [   1  946    0    1    0    1    0    0    0    3    1    0    2    1\n",
    "     7    0    0    0    0    0    0    0   12    2    2    0]\n",
    " [   4    0  173    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    1    0  397    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0  173    0    0    0    1    1    0    0    0    0\n",
    "     0    0    0    0    0    1    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0   88    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    1    0    0]\n",
    " [   0    0    0    0    0    0  224    1    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [  16    0    0    0    0    0    0  214    2    1    0    0    1    1\n",
    "     5    0    0    0    0    0    0    0    1    0    1    2]\n",
    " [   0    0    0    0    0    0    0    1  363    1    0    0    2    0\n",
    "     0    0    0    0    0    0    0    0    1    0    1    0]\n",
    " [   0    8    0    0    0    0    0    1    2  248    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    4    0    1    0]\n",
    " [   0    0    3    0    0    0    0    0    0    0  224    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    2    0    0    0    0    0    0    0    0  124    1    0\n",
    "     0    2    0    0    0    0    2    0    0    0    4    0]\n",
    " [   6    1    0    0    0    0    0    0    0    0    0    1  638    2\n",
    "     2    1    0    0    0    0    1    1    0    1   13    5]\n",
    " [   7    0    0    0    0    0    0    2    0    0    0    0    3 1044\n",
    "    14    0    0    0    0    0    0    1    0    2    0    0]\n",
    " [  29    3    3    0    0    0    0    3    0    1    1    0    2    8\n",
    "  1608    0    0    0    0    0    1    0    4    1    0    1]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    1    0\n",
    "     0  107    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    2    0\n",
    "     0    0    4    0    0    0    0    0    0    0    1    1]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0   74    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0  456    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    1 1264    0    0    1    0    0    0]\n",
    " [   2    0    0    0    0    1    0    0    0    0    0    3    1    3\n",
    "     2    0    0    0    0    0   84    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    1    0    0    1    0    0\n",
    "     0    0    0    0    0    1    0  305    0    0    0    1]\n",
    " [   5   14    0    0    0    0    0    0    0   23    0    0    2    1\n",
    "     7    0    0    0    0    1    0    0  651   16    5    0]\n",
    " [   2    3    0    0    3    1    0    0    1    3    0    0    0    1\n",
    "     5    0    0    0    0    0    0    0    6  377    1    0]\n",
    " [   0    0    0    0    0    0    0    0    2    0    0    3    6    0\n",
    "     1    0    0    0    0    0    1    0    0    0  482    0]\n",
    " [   0    0    0    1    0    0    0    0    0    0    0    0    0    1\n",
    "     1    0    0    0    1    0    0    0    0    0    0  635]]\n",
    "Time usage: 0:00:22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------分割线-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colab ouput old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "580it [00:00, 5795.92it/s]Loading data...\n",
    "96456it [00:15, 6046.62it/s]\n",
    "12051it [00:02, 5816.34it/s]\n",
    "12060it [00:01, 6554.05it/s]\n",
    "Time usage: 0:00:20\n",
    "Epoch [1/3]\n",
    "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
    "\tadd_(Number alpha, Tensor other)\n",
    "Consider using one of the following signatures instead:\n",
    "\tadd_(Tensor other, *, Number alpha)\n",
    "Iter:      0,  Train Loss:   3.3,  Train Acc:  3.12%,  Val Loss:   3.3,  Val Acc:  3.81%,  Time: 0:00:44 *\n",
    "Iter:    100,  Train Loss:  0.61,  Train Acc: 88.28%,  Val Loss:  0.58,  Val Acc: 85.79%,  Time: 0:03:50 *\n",
    "Iter:    200,  Train Loss:   0.3,  Train Acc: 92.97%,  Val Loss:  0.37,  Val Acc: 90.61%,  Time: 0:06:57 *\n",
    "Iter:    300,  Train Loss:  0.31,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 92.87%,  Time: 0:10:04 *\n",
    "Iter:    400,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.25,  Val Acc: 93.78%,  Time: 0:13:10 *\n",
    "Iter:    500,  Train Loss:  0.23,  Train Acc: 95.31%,  Val Loss:  0.22,  Val Acc: 94.33%,  Time: 0:16:16 *\n",
    "Iter:    600,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.21,  Val Acc: 94.71%,  Time: 0:19:22 *\n",
    "Iter:    700,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.19,  Val Acc: 95.25%,  Time: 0:22:28 *\n",
    "Epoch [2/3]\n",
    "Iter:    800,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.17,  Val Acc: 95.86%,  Time: 0:25:34 *\n",
    "Iter:    900,  Train Loss: 0.052,  Train Acc: 99.22%,  Val Loss:  0.16,  Val Acc: 95.68%,  Time: 0:28:39 *\n",
    "Iter:   1000,  Train Loss:   0.2,  Train Acc: 96.09%,  Val Loss:  0.15,  Val Acc: 96.17%,  Time: 0:31:45 *\n",
    "Iter:   1100,  Train Loss: 0.062,  Train Acc: 97.66%,  Val Loss:  0.14,  Val Acc: 96.32%,  Time: 0:34:51 *\n",
    "Iter:   1200,  Train Loss: 0.082,  Train Acc: 97.66%,  Val Loss:  0.14,  Val Acc: 96.32%,  Time: 0:37:56 \n",
    "Iter:   1300,  Train Loss:  0.29,  Train Acc: 94.53%,  Val Loss:  0.14,  Val Acc: 96.51%,  Time: 0:41:03 *\n",
    "Iter:   1400,  Train Loss: 0.064,  Train Acc: 98.44%,  Val Loss:  0.13,  Val Acc: 96.55%,  Time: 0:44:09 *\n",
    "Iter:   1500,  Train Loss:  0.11,  Train Acc: 97.66%,  Val Loss:  0.13,  Val Acc: 96.78%,  Time: 0:47:14 *\n",
    "Epoch [3/3]\n",
    "Iter:   1600,  Train Loss:   0.2,  Train Acc: 95.31%,  Val Loss:  0.12,  Val Acc: 96.83%,  Time: 0:50:20 *\n",
    "Iter:   1700,  Train Loss: 0.027,  Train Acc: 99.22%,  Val Loss:  0.12,  Val Acc: 97.07%,  Time: 0:53:26 *\n",
    "Iter:   1800,  Train Loss: 0.0079,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.20%,  Time: 0:56:31 *\n",
    "Iter:   1900,  Train Loss: 0.044,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.23%,  Time: 0:59:38 *\n",
    "Iter:   2000,  Train Loss: 0.011,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.20%,  Time: 1:02:44 *\n",
    "Iter:   2100,  Train Loss: 0.049,  Train Acc: 98.44%,  Val Loss:  0.11,  Val Acc: 97.37%,  Time: 1:05:50 *\n",
    "Iter:   2200,  Train Loss: 0.015,  Train Acc: 100.00%,  Val Loss:  0.11,  Val Acc: 97.29%,  Time: 1:08:57 *\n",
    "Test Loss:  0.11,  Test Acc: 97.33%\n",
    "Precision, Recall and F1-Score...\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        个人洗护     0.9354    0.9617    0.9484       783\n",
    "         保健品     0.9696    0.9765    0.9730       979\n",
    "        口腔护理     0.9670    0.9944    0.9805       177\n",
    "     女装/女士内衣     0.9900    0.9975    0.9938       399\n",
    "       婴幼儿奶粉     0.9669    0.9943    0.9804       176\n",
    "       孕产妇用品     0.9457    0.9775    0.9613        89\n",
    "     宝宝服饰/玩具     0.9825    1.0000    0.9912       225\n",
    "        宝宝洗护     0.9414    0.9221    0.9317       244\n",
    "   宝宝用品_含纸尿片     0.9785    0.9864    0.9825       369\n",
    "        宝宝食品     0.9104    0.9585    0.9338       265\n",
    "     宠物食品/用品     0.9956    0.9868    0.9912       227\n",
    "        家用家电     0.9769    0.9407    0.9585       135\n",
    "        居家日用     0.9758    0.9583    0.9670       672\n",
    "       彩妆/香水     0.9823    0.9814    0.9818      1073\n",
    "        护理护肤     0.9740    0.9664    0.9702      1665\n",
    "        数码3C     0.9727    0.9817    0.9772       109\n",
    "        汽车用品     1.0000    0.8889    0.9412         9\n",
    "          油品     0.9867    1.0000    0.9933        74\n",
    "     男装/男士内衣     0.9978    0.9978    0.9978       457\n",
    "       箱包/鞋靴     0.9984    0.9992    0.9988      1266\n",
    "        美容工具     0.9785    0.9479    0.9630        96\n",
    "        运动户外     0.9967    0.9871    0.9919       309\n",
    "        进口食品     0.9653    0.9214    0.9428       725\n",
    "        进口饮料     0.9513    0.9206    0.9357       403\n",
    "       餐厨/清洁     0.9476    0.9859    0.9663       495\n",
    "       饰品/手表     0.9906    0.9937    0.9922       639\n",
    "\n",
    "    accuracy                         0.9733     12060\n",
    "   macro avg     0.9722    0.9703    0.9710     12060\n",
    "weighted avg     0.9734    0.9733    0.9733     12060\n",
    "\n",
    "Confusion Matrix...\n",
    "[[ 753    0    0    0    0    0    1    7    1    0    0    0    0    2\n",
    "    17    0    0    0    0    0    0    0    1    1    0    0]\n",
    " [   1  956    0    1    1    1    0    0    0    5    0    0    1    1\n",
    "     3    0    0    0    0    0    0    0    5    1    2    1]\n",
    " [   1    0  176    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    1    0  398    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0  175    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    1    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0   87    0    1    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    1    0    0]\n",
    " [   0    0    0    0    0    0  225    0    0    0    0    0    0    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [  10    0    0    0    0    0    0  225    3    0    0    0    0    1\n",
    "     3    0    0    0    0    0    0    0    1    0    1    0]\n",
    " [   0    0    0    0    0    0    2    1  364    1    0    0    1    0\n",
    "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    2    0    0    1    0    0    1    2  254    0    0    0    1\n",
    "     0    0    0    0    0    0    0    0    4    0    0    0]\n",
    " [   0    0    2    0    0    0    0    0    0    0  224    0    0    0\n",
    "     1    0    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    1    0    0    0    0    0    1    0    0  127    2    0\n",
    "     0    1    0    0    0    0    1    0    0    0    2    0]\n",
    " [   3    1    0    0    0    0    1    0    0    0    0    0  644    2\n",
    "     1    0    0    0    0    0    1    0    0    1   14    4]\n",
    " [   6    0    0    0    0    0    0    1    0    0    0    0    2 1053\n",
    "     8    0    0    0    0    0    0    1    0    1    1    0]\n",
    " [  26    5    3    1    0    1    0    3    0    1    0    0    2    7\n",
    "  1609    0    0    0    0    0    0    0    7    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    1    0\n",
    "     0  107    0    0    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    8    0    0    0    0    0    0    0    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0   74    0    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
    "     0    0    0    0  456    0    0    0    0    0    0    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
    "     0    0    0    0    1 1265    0    0    0    0    0    0]\n",
    " [   1    0    0    0    0    1    0    0    0    0    0    1    0    1\n",
    "     0    0    0    0    0    0   91    0    0    0    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    0    2    0\n",
    "     0    1    0    0    0    0    0  305    1    0    0    0]\n",
    " [   3    9    0    0    0    0    0    0    0   16    1    0    2    0\n",
    "     6    1    0    0    0    1    0    0  668   14    4    0]\n",
    " [   1   12    0    0    4    2    0    0    1    2    0    0    0    2\n",
    "     2    0    0    0    0    0    0    0    5  371    1    0]\n",
    " [   0    0    0    0    0    0    0    0    0    0    0    1    3    0\n",
    "     1    0    0    1    0    0    0    0    0    0  488    1]\n",
    " [   0    0    0    2    0    0    0    0    0    0    0    0    0    1\n",
    "     1    0    0    0    0    0    0    0    0    0    0  635]]\n",
    "Time usage: 0:00:43"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.3",
   "language": "python",
   "name": "tf_2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
